# Iris Classification Streamlit App

## 📋 Requirements

Create a `requirements.txt` file with the following dependencies:

```txt
streamlit>=1.28.0
pandas>=1.5.0
numpy>=1.24.0
scikit-learn>=1.3.0
joblib>=1.3.0
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.15.0
scipy>=1.10.0
hpelm>=1.0.10
statsmodels>=0.14.0
lime>=0.2.0
shap>=0.42.0
```

## 🚀 Setup Instructions

### 1. Install Dependencies

```bash
# Create a virtual environment (recommended)
python -m venv iris_env
source iris_env/bin/activate  # On Windows: iris_env\Scripts\activate

# Install requirements
pip install -r requirements.txt
```

### 2. File Structure

Ensure your project directory has this structure:

```
iris_project/
│
├── app.py                    # Main Streamlit app
├── requirements.txt          # Dependencies
├── your_training_script.py   # Your original ML script
│
├── Models/ (generated after training)
│   ├── iris_rf_model.pkl
│   ├── best_svm_model.pkl
│   ├── scaler.pkl
│   └── label_encoder.pkl
│
└── README.md
```

### 3. Train Your Models First

Before running the Streamlit app, execute your original training script to generate the model files:

```bash
python your_training_script.py
```

This will create the required `.pkl` files that the Streamlit app needs.

### 4. Run the Streamlit App

```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

## 🎯 App Features

### 🏠 Home & Prediction Page
- **Interactive Sliders**: Adjust sepal and petal measurements
- **Real-time Predictions**: Get predictions from Random Forest and SVM models
- **Confidence Scores**: View prediction probabilities
- **Quick Examples**: Try pre-defined flower measurements
- **Model Agreement**: See if both models agree on the prediction

### 📊 Data Exploration Page
- **Dataset Overview**: Basic statistics and information
- **Raw Data Display**: View the actual iris dataset
- **Statistical Summary**: Descriptive statistics for all features
- **Interactive Visualizations**: 
  - Feature distribution plots
  - Correlation matrix heatmap
  - Species comparison box plots

### 📈 Model Performance Page
- **Performance Metrics Table**: Accuracy, precision, recall, F1-score
- **Comparative Charts**: Bar charts for accuracy and training time
- **Radar Chart**: Comprehensive model comparison visualization

### 🔍 Feature Analysis Page
- **Feature Importance**: Bar chart showing which features matter most
- **Pairwise Relationships**: Scatter matrix of all features
- **3D Visualization**: Interactive 3D scatter plot with customizable axes

## 🎨 Customization Options

### Styling
The app includes custom CSS for:
- Colorful prediction results based on species
- Metric cards with professional styling
- Responsive layout design

### Adding New Models
To add more models to the app:

1. Train and save your new model as a `.pkl` file
2. Load it in the `load_models()` function
3. Add prediction logic in the `make_predictions()` function
4. Update the performance metrics

### Adding New Features
To add new analysis features:

1. Create a new function for your feature
2. Add it to the sidebar navigation
3. Call it in the main() function

## 🔧 Troubleshooting

### Common Issues

**1. Model files not found**
- Ensure you've run the training script first
- Check that all `.pkl` files are in the same directory as `app.py`

**2. Import errors**
- Verify all packages are installed: `pip install -r requirements.txt`
- Check Python version compatibility (Python 3.8+ recommended)

**3. Streamlit not starting**
- Try: `python -m streamlit run app.py`
- Check if port 8501 is available

**4. Performance issues**
- The app uses caching (`@st.cache_resource`, `@st.cache_data`) for better performance
- Large datasets might need additional optimization

## 📱 Deployment Options

### Local Development
```bash
streamlit run app.py
```

### Streamlit Cloud
1. Push your code to GitHub
2. Connect your GitHub repo to Streamlit Cloud
3. Deploy with one click

### Heroku
1. Add `Procfile`: `web: streamlit run app.py --server.port=$PORT --server.address=0.0.0.0`
2. Deploy to Heroku

### Docker
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8501

CMD ["streamlit", "run", "app.py", "--server.address", "0.0.0.0"]
```

## 🎯 Next Steps

1. **Enhanced Visualizations**: Add more interactive plots
2. **Batch Predictions**: Upload CSV files for multiple predictions
3. **Model Comparison**: Add more ML algorithms
4. **Feature Engineering**: Include PCA or other dimensionality reduction
5. **Export Results**: Add functionality to download predictions
6. **User Authentication**: Add login system for personalized experience

## 📝 Usage Tips

- Use the sliders to explore how different measurements affect predictions
- Try the example buttons to see typical values for each species
- Check the Data Exploration page to understand the dataset better
- Use the 3D visualization to see how features separate the species
- Monitor model agreement to understand prediction confidence